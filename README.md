# SCRIPT.IA ‚Äì G√©n√©rateur de Rapports Automatique üöÄ

![Python](https://img.shields.io/badge/Python-3.13+-3776AB?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115-009688?logo=fastapi&logoColor=white)
![React](https://img.shields.io/badge/React-18.3-61DAFB?logo=react&logoColor=white)
![Version](https://img.shields.io/badge/Version-2.0.0-0A0A0A)
![Status](https://img.shields.io/badge/LLM-Ollama-brightgreen)

Syst√®me complet de g√©n√©ration automatique de rapports pour clients, utilisant l'IA locale (Ollama) pour cr√©er des documents professionnels au format DOCX.

## üéØ D√©marrage Rapide - UN CLIC

### D√©marrer tous les services

```bash
./scripts/start-all.sh
```

Ce script unique lance automatiquement :
- ‚úÖ V√©rification de Redis et Ollama
- ‚úÖ Worker RQ pour le traitement en arri√®re-plan
- ‚úÖ Backend FastAPI (API REST)
- ‚úÖ Frontend React (interface utilisateur)
- ‚úÖ Ouverture du navigateur sur http://localhost:5173

### Arr√™ter tous les services

```bash
./scripts/stop.sh
```

## üì± Acc√®s aux Services

| Service | URL | Description |
|---------|-----|-------------|
| **Frontend** | http://localhost:5173 | Interface utilisateur React |
| **Backend** | http://localhost:8000/api/health | API REST FastAPI |
| **API Docs** | http://localhost:8000/api/docs | Documentation Swagger interactive |
| **Login** | admin / admin123 | Identifiants de test |

## üîÑ Workflow de G√©n√©ration - UN CLIC

1. **Ouvrez le navigateur** : http://localhost:5173
2. **S√©lectionnez un client** : Choisissez dans la liste d√©roulante
3. **Cliquez sur "G√©n√©rer le Rapport"** : Un seul clic suffit !
4. **Le syst√®me ex√©cute automatiquement** :
   - üìÇ Extraction des donn√©es depuis les fichiers .msg et documents
   - ü§ñ G√©n√©ration de contenu par l'IA (Mistral/LLaMA)
   - üìù Remplissage du template DOCX
   - üíæ Sauvegarde du rapport final

5. **T√©l√©chargez le DOCX** : Cliquez sur "T√©l√©charger" quand le statut est "completed"

## üõ†Ô∏è Architecture du Syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Frontend React ‚îÇ  ‚Üê Interface utilisateur (port 5173)
‚îÇ   (Vite + TS)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Backend API    ‚îÇ  ‚Üê Orchestrateur (port 8000)
‚îÇ   (FastAPI)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Redis Queue
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker RQ      ‚îÇ  ‚Üê Traitement asynchrone
‚îÇ                 ‚îÇ
‚îÇ  1. Extraction  ‚îÇ‚îÄ‚îÄ‚ñ∫ extract_sources.py (68KB de donn√©es)
‚îÇ  2. G√©n√©ration  ‚îÇ‚îÄ‚îÄ‚ñ∫ Ollama LLM (~1m35s avec Mistral)
‚îÇ  3. Rendu DOCX  ‚îÇ‚îÄ‚îÄ‚ñ∫ python-docx (37KB final)
‚îÇ  4. Export PDF  ‚îÇ‚îÄ‚îÄ‚ñ∫ docx2pdf (optionnel)
‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üì¶ Pr√©requis

### Services Requis

1. **Redis** (file d'attente de t√¢ches)
   ```bash
   brew install redis
   brew services start redis
   ```

2. **Ollama** (mod√®les LLM locaux)
   ```bash
   brew install ollama
   ollama serve
   ollama pull mistral  # ou llama3.1
   ```

3. **Node.js** (frontend)
   ```bash
   brew install node
   ```

4. **Python 3.13+** (backend)
   ```bash
   brew install python@3.13
   ```

### Installation des D√©pendances

```bash
# Backend Python
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Frontend Node
cd frontend
npm install
```

## üìä Suivi de l'Ex√©cution

### Logs en Temps R√©el

```bash
# Worker (traitement des t√¢ches)
tail -f /tmp/worker.log

# Backend (API)
tail -f /tmp/backend.log

# Frontend (interface)
tail -f /tmp/frontend.log
```

### V√©rification de l'√âtat

```bash
# Health check backend
curl http://localhost:8000/api/health

# Liste des clients disponibles
curl http://localhost:8000/api/clients

# Statut d'un rapport
curl http://localhost:8000/api/reports/{report_id}/status
```

## üîê Authentification JWT

Le syst√®me utilise JWT pour s√©curiser l'API :

```bash
# Login
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"admin123"}'

# R√©ponse
{
  "access_token": "eyJhbGc...",
  "token_type": "bearer",
  "expires_in": 3600
}

# Utilisation du token
curl http://localhost:8000/api/reports \
  -H "Authorization: Bearer eyJhbGc..."
```

### Utilisateurs de Test

| Username | Password | R√¥le |
|----------|----------|------|
| admin | admin123 | Administrateur (tous droits) |
| user | user123 | Utilisateur (lecture seule) |

## üìù Structure des Rapports

### Template DOCX

Le fichier template se trouve dans :
```
CLIENTS/templates/template_rapport.docx
```

### Champs Dynamiques

Les marqueurs suivants sont remplac√©s automatiquement :

- `{{nom_prenom}}` - Nom complet du client
- `{{date_bilan}}` - Date du bilan
- `{{competences_transferables}}` - Liste des comp√©tences
- `{{projet_professionnel}}` - Description du projet
- `{{plan_action}}` - Plan d'action d√©taill√©
- ... et 20+ autres champs

### Sources de Donn√©es

Le syst√®me extrait automatiquement depuis :
- üìß Fichiers .msg (emails Outlook)
- üìÑ Documents Word (.docx)
- üìä PDFs de tests psychom√©triques
- üìë Bulletins de salaire
- üéì Dipl√¥mes et certificats

## üß™ Tests

### Lancer les Tests Unitaires

```bash
# Installation des d√©pendances de test
pip install -r tests/requirements.txt

# Ex√©cution avec couverture
pytest tests/ -v --cov=backend --cov-report=term-missing

# Tests sp√©cifiques
pytest tests/test_api.py::TestReportsRoutes::test_create_report -v
```

### Tests Manuels via Swagger

1. Ouvrez http://localhost:8000/api/docs
2. Testez les endpoints interactivement
3. Utilisez "Authorize" avec un token JWT

## üêõ D√©pannage

### Redis n'est pas accessible

```bash
# V√©rifier Redis
redis-cli ping  # Devrait r√©pondre "PONG"

# Red√©marrer Redis
brew services restart redis
```

### Ollama ne r√©pond pas

```bash
# V√©rifier Ollama
curl http://localhost:11434/api/version

# Relancer Ollama
ollama serve &

# V√©rifier les mod√®les
ollama list
```

### Worker ne traite pas les t√¢ches

```bash
# V√©rifier les logs
tail -f /tmp/worker.log

# V√©rifier la queue Redis
redis-cli
> LLEN rq:queue:default
> LRANGE rq:queue:default 0 -1

# Red√©marrer le worker
pkill -f start_worker.py
.venv/bin/python scripts/start_worker.py &
```

### Frontend ne se connecte pas au backend

1. V√©rifiez que le backend tourne : `curl http://localhost:8000/api/health`
2. V√©rifiez les CORS dans `backend/core/config.py`
3. Inspectez la console navigateur (F12)

## üåê D√©ploiement Windows

Consultez le guide complet : [docs/WINDOWS_DEPLOYMENT.md](docs/WINDOWS_DEPLOYMENT.md)

R√©sum√© :
- Installation avec `winget` et PowerShell
- Redis via WSL2 ou Memurai
- Services Windows avec NSSM
- Scripts PowerShell automatis√©s

## üìä Performance

### Temps de G√©n√©ration Typiques

| √âtape | Dur√©e | D√©tails |
|-------|-------|---------|
| Extraction | ~2-5s | Lecture fichiers .msg + PDFs |
| G√©n√©ration LLM | ~1m30s | Mistral 7B (varie selon mod√®le) |
| Rendu DOCX | ~1-2s | python-docx |
| **Total** | **~2min** | Pour un rapport complet |

### Optimisations

- **Mod√®le plus rapide** : `ollama pull llama3.1:8b` (30% plus rapide)
- **GPU** : Ollama utilise automatiquement Metal/CUDA
- **Cache Redis** : R√©utilise les extractions existantes

## üîß Configuration Avanc√©e

### Variables d'Environnement

Cr√©ez `.env` √† la racine :

```env
# API
API_HOST=0.0.0.0
API_PORT=8000
API_PREFIX=/api

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=mistral:latest

# JWT
SECRET_KEY=votre-cl√©-secr√®te-changez-moi
ACCESS_TOKEN_EXPIRE_MINUTES=60

# Logging
LOG_LEVEL=INFO
```

### Personnalisation du Template

1. Modifiez `CLIENTS/templates/template_rapport.docx`
2. Ajoutez vos propres marqueurs `{{nouveau_champ}}`
3. Mettez √† jour `CLIENTS/generate_fields.py` pour g√©n√©rer le contenu

## üìö Documentation Compl√®te

- **API Backend** : http://localhost:8000/api/docs (Swagger)
- **Tests** : [tests/README.md](tests/README.md)
- **Windows** : [docs/WINDOWS_DEPLOYMENT.md](docs/WINDOWS_DEPLOYMENT.md)

## ü§ù Support

Pour toute question ou probl√®me :
1. Consultez les logs : `tail -f /tmp/*.log`
2. V√©rifiez les services : `./scripts/start-all.sh`
3. Testez l'API : http://localhost:8000/api/docs

## üìÑ Licence

Projet interne - Tous droits r√©serv√©s
