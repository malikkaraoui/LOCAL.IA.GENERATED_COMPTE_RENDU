# SCRIPT.IA - Sprint 3: Backend/Frontend Separation

## ğŸ—ï¸ Architecture

```
SCRIPT.IA/
â”œâ”€â”€ backend/              # FastAPI Backend
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/      # Endpoints REST
â”‚   â”‚   â””â”€â”€ models/      # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ workers/         # RQ Workers
â”‚   â”œâ”€â”€ config.py        # Configuration
â”‚   â””â”€â”€ main.py          # Application FastAPI
â”‚
â”œâ”€â”€ frontend/            # React + Vite Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/      # Pages (ClientSelection, Progress)
â”‚   â”‚   â”œâ”€â”€ services/   # API Client
â”‚   â”‚   â””â”€â”€ App.jsx     # Router principal
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ core/                # Logique mÃ©tier existante
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ generate.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â””â”€â”€ errors.py       # Result[T] pattern
â”‚
â””â”€â”€ tests/               # Tests (194 tests, 50% coverage)
```

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis

1. **Python 3.11+** avec environnement virtuel activÃ©
2. **Node.js 18+** et npm
3. **Redis** (pour la queue de jobs)
4. **Ollama** avec modÃ¨le qwen2.5:latest

### Installation

```bash
# 1. DÃ©pendances Python
pip install -r requirements.txt

# 2. DÃ©pendances frontend
cd frontend
npm install
cd ..
```

### Configuration

CrÃ©er un fichier `.env` Ã  la racine :

```env
# Serveur
HOST=0.0.0.0
PORT=8000

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:latest
OLLAMA_TIMEOUT=120

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Chemins
CLIENTS_DIR=./CLIENTS
OUTPUT_DIR=./output
```

### Lancement (4 terminaux requis)

#### Terminal 1: Redis
```bash
redis-server
```

#### Terminal 2: RQ Worker
```bash
python scripts/start_worker.py
```

#### Terminal 3: Backend FastAPI
```bash
python -m backend.main
```

#### Terminal 4: Frontend React
```bash
cd frontend
npm run dev
```

### AccÃ¨s

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

## ğŸ“¡ API Endpoints

### Health
- `GET /health` - Status gÃ©nÃ©ral
- `GET /health/ollama` - Status Ollama

### Reports
- `POST /reports` - CrÃ©er un rapport (retourne job_id)
- `GET /reports/{job_id}` - Statut du rapport
- `GET /reports/{job_id}/stream` - SSE streaming (temps rÃ©el)
- `GET /reports/{job_id}/download` - TÃ©lÃ©charger DOCX
- `DELETE /reports/{job_id}` - Supprimer un job

## ğŸ”„ Workflow

1. **Utilisateur** : SÃ©lectionne un client sur le frontend
2. **Frontend** : POST /reports â†’ reÃ§oit job_id
3. **Backend** : Enqueue job dans Redis Queue
4. **RQ Worker** : Traite le job (extraction, gÃ©nÃ©ration, rendu)
5. **Frontend** : SSE streaming pour suivi en temps rÃ©el
6. **Utilisateur** : TÃ©lÃ©charge le DOCX une fois terminÃ©

## ğŸ§ª Tests

```bash
# Tous les tests (194 tests, 50% coverage)
pytest

# Coverage report
pytest --cov=. --cov-report=html
```

## ğŸ“¦ Technologies

- **Backend**: FastAPI, Redis, RQ, Pydantic, Uvicorn
- **Frontend**: React, Vite, React Router, Axios
- **Queue**: Redis + RQ (Python)
- **LLM**: Ollama (qwen2.5:latest)
- **Tests**: pytest, coverage

## ğŸ” SÃ©curitÃ© (TODO Sprint 3.5)

- JWT authentication
- Token refresh
- Protected routes
- CORS configuration

## ğŸªŸ DÃ©ploiement Windows (TODO Sprint 3.7)

- IIS pour frontend statique
- FastAPI comme service Windows (NSSM)
- Redis comme service Windows
- Reverse proxy IIS â†’ FastAPI
- HTTPS avec certificat

## ğŸ“ Sprint 3 Status

âœ… **TerminÃ©**:
- Backend FastAPI avec CRUD complet
- Redis + RQ pour jobs asynchrones
- Frontend React + Vite avec routing
- Pages: ClientSelection, Progress
- SSE streaming pour temps rÃ©el
- API service avec Axios

â³ **En cours**:
- Tests d'intÃ©gration complÃ¨te

âŒ **Ã€ faire**:
- JWT authentication
- Upload de fichiers
- Historique des rapports
- Tests backend
- Documentation dÃ©ploiement Windows

## ğŸ› Troubleshooting

### Redis connection refused
```bash
# macOS
brew services start redis

# Linux
sudo systemctl start redis
```

### Ollama not available
```bash
# DÃ©marrer Ollama
ollama serve

# VÃ©rifier le modÃ¨le
ollama list
ollama pull qwen2.5:latest
```

### Port already in use
```bash
# Changer le port dans .env
PORT=8001

# Ou tuer le processus
lsof -ti:8000 | xargs kill -9
```

## ğŸ“š Documentation Sprint 2

- [Sprint 2 Report](docs/sprint2-report.md) - Architecture Result[T]
- [Sprint 2 Guide](docs/sprint2-guide.md) - Guide d'utilisation

---

**Version**: Sprint 3.0  
**Auteur**: SCRIPT.IA Team  
**Date**: 2024
