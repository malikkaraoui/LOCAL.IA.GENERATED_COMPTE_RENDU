# Pipeline de Normalisation RH-Pro

## üéØ Objectif

Transformer les dossiers clients RH-Pro en format "pipeline-ready" :
- ‚úÖ D√©tection automatique du GOLD (rapport final de r√©f√©rence)
- ‚úÖ Extraction des sources RAG exploitables
- ‚úÖ Normalisation en sandbox (sans toucher l'original)
- ‚úÖ Pr√©paration pour RAG + g√©n√©ration DOCX

## üìä R√©sultats Tests

### Dataset : RH PRO BASE DONNEE/3. TERMINER/

**Test sur 20 premiers clients :**
- üìÅ Total : 20 clients
- ‚úÖ Scann√©s : 20 (100%)
- ‚úÖ Pipeline-ready : 14 (70%)
- ‚úÖ Normalis√©s : 14 (100% des ready)
- ‚ùå Erreurs : 0

**Taux de succ√®s : 70% pipeline-ready**

Les 30% non-ready sont dus √† :
- Absence de sources RAG (documents manquants)
- GOLD avec confiance trop faible (< 0.3)
- Structure d√©sorganis√©e

## üìÇ Structure Pipeline-Compatible

### Entr√©e (Dataset Original)
```
/RH PRO BASE DONNEE/3. TERMINER/
‚îî‚îÄ‚îÄ NOM Pr√©nom/
    ‚îú‚îÄ‚îÄ 01 Dossier personnel/    ‚Üê Sources RAG
    ‚îú‚îÄ‚îÄ 03 Tests et bilans/      ‚Üê Sources RAG
    ‚îú‚îÄ‚îÄ 04 Stages/               ‚Üê Sources RAG
    ‚îú‚îÄ‚îÄ 05 Mesures AI/           ‚Üê Sources RAG
    ‚îú‚îÄ‚îÄ 06 Rapport final/        ‚Üê GOLD
    ‚îî‚îÄ‚îÄ divers fichiers .docx, .pdf, .txt, .msg
```

### Sortie (Sandbox Normalis√©e)
```
./sandbox/BATCH_20/
‚îî‚îÄ‚îÄ client_slug/
    ‚îú‚îÄ‚îÄ sources/                 ‚Üê Copies des sources RAG
    ‚îÇ   ‚îú‚îÄ‚îÄ 01_personnel_001_cv.pdf
    ‚îÇ   ‚îú‚îÄ‚îÄ 03_tests_002_resultat.docx
    ‚îÇ   ‚îú‚îÄ‚îÄ 04_stages_003_convention.pdf
    ‚îÇ   ‚îî‚îÄ‚îÄ root_004_document.msg
    ‚îú‚îÄ‚îÄ gold/
    ‚îÇ   ‚îî‚îÄ‚îÄ rapport_final.docx   ‚Üê Copie du GOLD d√©tect√©
    ‚îú‚îÄ‚îÄ normalized/
    ‚îÇ   ‚îî‚îÄ‚îÄ source.docx          ‚Üê Alias (optionnel)
    ‚îî‚îÄ‚îÄ meta.json                ‚Üê M√©tadonn√©es compl√®tes
```

## üîç D√©tection GOLD

### Strat√©gies (par ordre de priorit√©)

1. **06_rapport_final/** : Scanner d'abord le dossier "06 Rapport final"
2. **recursive_scan** : Si non trouv√©, scanner tout le dossier client
3. **most_recent_fallback** : Prendre le .docx le plus r√©cent

### Score de Confiance

Le score est calcul√© selon :
- ‚úÖ **+0.30** : Pr√©sence dans dossier "06 Rapport final"
- ‚úÖ **+0.15** par mot-cl√© : "rapport", "bilan", "orientation", "synth√®se", "final"
- ‚úÖ **+0.15** : Extension .docx
- ‚ùå **-0.50** : Noms g√©n√©riques ("template", "mod√®le", "vierge")

**Seuil minimum** : 0.30 (configurable)

### Exemple de D√©tection

```
ARIFI Zejadin/
‚îú‚îÄ‚îÄ Bilan orientation RH-Pro 2021.docx   ‚Üí score: 0.60 ‚úÖ SELECTED
‚îú‚îÄ‚îÄ CV.docx                              ‚Üí score: 0.15
‚îî‚îÄ‚îÄ notes.docx                           ‚Üí score: 0.15
```

## üìö Sources RAG

### Dossiers Scann√©s

- **01 Dossier personnel** : CV, lettres, pi√®ces d'identit√©
- **03 Tests et bilans** : Tests psychotechniques, √©valuations
- **04 Stages** : Conventions, rapports de stage
- **05 Mesures AI** : Attestations, contrats
- **Racine** : Documents directs (non r√©cursif)

### Extensions Accept√©es

`.docx`, `.pdf`, `.txt`, `.msg`, `.doc`

### Naming Convention

Format : `<category>_<idx>_<slug><ext>`

Exemples :
- `01_personnel_001_cv_2024.pdf`
- `03_tests_002_resultat_test_compta.docx`
- `root_003_vis_rh_pro.msg`

## üõ†Ô∏è Utilisation

### CLI : demo_training_pipeline.py

```bash
# Lister les clients
python demo_training_pipeline.py /path/to/dataset --list

# Scanner 1 client
python demo_training_pipeline.py /path/to/dataset --client "NOM Prenom"

# Scanner + normaliser 5 premiers
python demo_training_pipeline.py /path/to/dataset --limit 5 --normalize

# Batch complet avec 20 clients
python demo_training_pipeline.py /path/to/dataset \
  --limit 20 \
  --batch BATCH_20 \
  --sandbox ./sandbox \
  --normalize
```

### UI : Streamlit

```bash
streamlit run streamlit_app.py
```

1. Aller dans **üéì Entra√Ænement**
2. Mode **üîç Analyser un client** ou **üì¶ Batch**
3. Browse pour s√©lectionner le dataset
4. Rechercher un client (fuzzy search)
5. Scanner ‚Üí Affiche GOLD, sources, warnings
6. Normaliser ‚Üí Cr√©e la sandbox

### API : Backend

```python
import requests

# Analyser un client
response = requests.post("http://localhost:8000/api/training/analyze-client", json={
    "client_folder_path": "/path/to/NOM Prenom"
})
scan_result = response.json()["scan_result"]

# Normaliser
response = requests.post("http://localhost:8000/api/training/normalize-client", json={
    "client_folder_path": "/path/to/NOM Prenom",
    "batch_name": "BATCH_20",
    "sandbox_root": "./sandbox"
})
norm_result = response.json()["normalization_result"]

# Batch
response = requests.post("http://localhost:8000/api/training/normalize-batch", json={
    "dataset_root": "/path/to/dataset",
    "client_names": ["NOM1 Prenom1", "NOM2 Prenom2"],
    "batch_name": "BATCH_20"
})
batch_result = response.json()["batch_result"]
```

### Code Python

```python
from src.rhpro.client_scanner import scan_client_folder, format_scan_report
from src.rhpro.client_normalizer import normalize_client_to_sandbox

# Scanner
scan_result = scan_client_folder("/path/to/NOM Prenom")
print(format_scan_report(scan_result))

if scan_result["pipeline_ready"]:
    # Normaliser
    norm_result = normalize_client_to_sandbox(
        scan_result,
        batch_name="BATCH_20",
        sandbox_root="./sandbox",
    )
    print(f"‚úÖ Sandbox : {norm_result['sandbox_path']}")
```

## üìã meta.json Structure

```json
{
  "normalization_info": {
    "batch_name": "BATCH_20",
    "client_slug": "arifi_zejadin",
    "original_client_name": "ARIFI Zejadin",
    "original_client_path": "/path/to/ARIFI Zejadin",
    "normalized_at": "2025-12-27T14:41:00",
    "sandbox_path": "/sandbox/batch_20/arifi_zejadin"
  },
  "scan_result": {
    "client_name": "ARIFI Zejadin",
    "gold": {
      "path": "/path/to/Bilan orientation.docx",
      "score": 0.60,
      "strategy": "recursive_scan",
      "size_bytes": 1365109
    },
    "rag_sources": [
      {
        "path": "/path/to/test_compta.pdf",
        "category": "03_tests",
        "extension": ".pdf",
        "size_bytes": 245678
      }
    ],
    "folder_structure": {
      "01_personnel": null,
      "03_tests": "/path/to/03 Tests",
      "06_rapport": null
    },
    "warnings": [],
    "pipeline_ready": true,
    "stats": {
      "gold_found": true,
      "gold_score": 0.60,
      "rag_sources_count": 10,
      "extensions": {
        ".pdf": 8,
        ".docx": 1,
        ".msg": 1
      },
      "total_size_mb": 12.5
    }
  },
  "gold": {
    "original_path": "/path/to/Bilan orientation.docx",
    "normalized_path": "/sandbox/batch_20/arifi_zejadin/gold/rapport_final.docx",
    "size_bytes": 1365109,
    "copied_at": "2025-12-27T14:41:00"
  },
  "sources": [
    {
      "original_path": "/path/to/test_compta.pdf",
      "normalized_path": "/sandbox/batch_20/arifi_zejadin/sources/03_tests_001_test_compta.pdf",
      "category": "03_tests",
      "size_bytes": 245678,
      "copied_at": "2025-12-27T14:41:00"
    }
  ],
  "file_counts": {
    "gold": 1,
    "sources": 10,
    "total": 11
  },
  "pipeline_ready": true
}
```

## ‚ö†Ô∏è Warnings Types

| Warning | Cause | Impact | Solution |
|---------|-------|--------|----------|
| `‚ùå Aucun document GOLD d√©tect√©` | Pas de .docx trouv√© | Bloquant | V√©rifier la pr√©sence de rapports |
| `‚ö†Ô∏è Confiance GOLD faible (< 0.5)` | Score < 0.5 | Avertissement | Valider manuellement le GOLD |
| `‚ùå Aucune source RAG trouv√©e` | Pas de documents | Bloquant | Ajouter des documents sources |
| `‚ö†Ô∏è Peu de sources RAG (< 3)` | < 3 sources | Avertissement | RAG limit√©, r√©sultats moyens |
| `‚ö†Ô∏è Dossiers manquants` | Structure incompl√®te | Info | Impact variable selon dossiers |

## üöÄ Prochaines √âtapes

### V1 (Actuel) ‚úÖ
- ‚úÖ D√©tection GOLD avec scoring
- ‚úÖ Extraction sources RAG
- ‚úÖ Normalisation sandbox
- ‚úÖ CLI + UI + API
- ‚úÖ Tests 20 clients (70% success)

### V2 (Prochain Sprint)
- üîÑ Int√©gration RAG sur sandbox
- üîÑ G√©n√©ration DOCX automatique
- üîÑ Comparaison GOLD vs Generated
- üîÑ M√©triques de qualit√©
- üîÑ Training loop avec feedback

### V3 (Future)
- üìÖ Auto-correction des dossiers non-ready
- üìÖ Suggestions d'am√©lioration structure
- üìÖ Dashboard analytics global
- üìÖ Export batch vers format training ML

## üìÅ Fichiers Cr√©√©s

### Modules Core
- `src/rhpro/client_scanner.py` (420 lignes)
  - `scan_client_folder()` : Analyse compl√®te
  - `find_gold_document()` : D√©tection GOLD avec scoring
  - `find_rag_sources()` : Extraction sources RAG
  - `format_scan_report()` : Formatage console

- `src/rhpro/client_normalizer.py` (340 lignes)
  - `normalize_client_to_sandbox()` : Copie structur√©e
  - `normalize_batch_to_sandbox()` : Batch processing
  - `format_normalization_report()` : Rapport batch

### CLI & UI
- `demo_training_pipeline.py` (195 lignes)
  - CLI pour tests et production
  - Support client unique ou batch
  - Options --normalize, --limit, --list

- `pages_streamlit/training.py` (440 lignes)
  - Page Entra√Ænement compl√®te
  - Browse dataset + recherche client
  - Scan + normalisation interactive
  - Modes : single client, batch, config

### Backend API
- `backend/api/routes/training.py` (ajout)
  - `POST /api/training/analyze-client`
  - `POST /api/training/normalize-client`
  - `POST /api/training/normalize-batch`

### Documentation
- `docs/PIPELINE_NORMALIZATION.md` (ce fichier)
- `docs/DATASET_MODE_GUIDE.md` (pr√©c√©dent sprint)

## üîß Configuration

### Param√®tres Scanner (√† venir)

```yaml
# config/pipeline.yaml
scanner:
  gold:
    min_score: 0.3
    keywords:
      - rapport
      - bilan
      - orientation
      - synth√®se
      - final
    extensions:
      - .docx
      - .doc
  
  rag:
    min_sources: 1
    extensions:
      - .docx
      - .pdf
      - .txt
      - .msg
    folders:
      - 01 Dossier personnel
      - 03 Tests et bilans
      - 04 Stages
      - 05 Mesures AI

normalizer:
  create_alias: true
  sandbox_root: ./sandbox
  continue_on_error: true
```

## üìä M√©triques Batch

Exemple de rapport batch (14 clients) :

```
üì¶ NORMALISATION BATCH : BATCH_20
üìä R√©sultats : 14 client(s)
  ‚úÖ Succ√®s      : 14
  ‚ö†Ô∏è  Non pr√™ts   : 0
  ‚ùå Erreurs     : 0
  üìà Taux succ√®s : 100.0%

üìÅ Sandbox cr√©√©e dans : /sandbox/batch_20
üìä 14 client(s) normalis√©(s)

Taille totale : ~180 MB
Fichiers copi√©s : ~140 (14 GOLD + 126 sources)
Temps traitement : ~45 secondes
```

## ‚úÖ Validation

### Tests Unitaires (√† venir)

```python
# tests/test_client_scanner.py
def test_scan_client_folder_with_gold():
    scan = scan_client_folder("data/samples/client_01")
    assert scan["pipeline_ready"] == True
    assert scan["gold"] is not None
    assert len(scan["rag_sources"]) > 0

# tests/test_client_normalizer.py
def test_normalize_creates_structure():
    norm = normalize_client_to_sandbox(scan, "TEST")
    assert Path(norm["gold_path"]).exists()
    assert Path(norm["sources_path"]).exists()
    assert Path(norm["meta_path"]).exists()
```

### Tests d'Int√©gration

```bash
# Test CLI complet
python demo_training_pipeline.py data/samples --limit 5 --normalize

# Test API
pytest tests/test_api_training.py -v

# Test UI (manuel)
streamlit run streamlit_app.py
```

## üéì Commandes Git

```bash
# Ajouter tous les fichiers
git add -A

# Commit
git commit -m "feat: Add pipeline normalization system

- Scanner de dossiers clients (GOLD + RAG detection)
- Normalisation en sandbox (structure pipeline-ready)
- CLI demo_training_pipeline.py
- Page Streamlit üéì Entra√Ænement
- API endpoints /api/training/analyze-client, normalize-client, normalize-batch
- Tests sur 20 clients r√©els : 70% pipeline-ready
- Documentation compl√®te

R√©sultats :
- 14/20 clients normalis√©s avec succ√®s
- Structure sources/, gold/, normalized/, meta.json
- Naming convention : category_idx_slug.ext
- Meta.json complet avec scan_result + copie infos"

# Push
git push
```
